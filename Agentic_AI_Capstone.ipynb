{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# PDF AUDIT AGENT SCRIPT\n",
        "# Purpose: Compares a local JSON data entry against the content of a PDF\n",
        "# (acting as the ground truth) using the Gemini API's enforced JSON output.\n",
        "# The script determines if the local data needs correction and allows the\n",
        "# user to persist the changes.\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "# --- Standard Library Imports ---\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import fitz # PyMuPDF library for efficient PDF reading\n",
        "import re\n",
        "from typing import Dict, Any, Optional\n",
        "# Note: The provided imports were missing typing hints, adding them for clarity\n",
        "# from typing import Dict, Any, Optional is assumed/added for best practice.\n",
        "\n",
        "# --- Third-Party Library Imports ---\n",
        "from google import genai\n",
        "from google.genai.errors import APIError\n",
        "\n",
        "# -----------------------\n",
        "# Configuration & Paths\n",
        "# -----------------------\n",
        "# --- API and Model Setup ---\n",
        "# The API key is sourced from environment variables, falling back to a placeholder.\n",
        "GEMINI_API_KEY = os.environ.get(\"GEMINI_API_KEY\", \"ENTER YOUR API KEY\")\n",
        "client = genai.Client(api_key=GEMINI_API_KEY)\n",
        "MODEL = \"gemini-2.5-flash\"\n",
        "\n",
        "# --- File Paths and Operational Settings ---\n",
        "JSON_PATH = \"scheme_details.json\" # Path to the local data entry to be audited\n",
        "PDF_PATH = \"scheme_pdf.pdf\" # Path to the PDF file (the ground truth)\n",
        "MAX_RETRIES = 3 # Maximum attempts for the LLM API call in case of transient errors\n",
        "\n",
        "# --- RESPONSE SCHEMA DEFINITION ---\n",
        "# This schema defines the structure the LLM MUST return (JSON Mode) for\n",
        "# guaranteed validation. It includes the corrected data and a summary of changes.\n",
        "RESPONSE_SCHEMA: Dict[str, Any] = {\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "        \"corrected_entry\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"headline\": {\"type\": \"string\"},\n",
        "                \"summary\": {\"type\": \"string\"},\n",
        "                \"important_points\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
        "                \"eligibility_rules\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
        "                \"category\": {\"type\": \"string\"},\n",
        "                \"date\": {\"type\": \"string\"},\n",
        "                \"source_url\": {\"type\": \"string\"},\n",
        "            },\n",
        "            \"required\": [\"headline\", \"summary\", \"important_points\", \"eligibility_rules\", \"category\", \"date\", \"source_url\"],\n",
        "        },\n",
        "        \"changes_summary\": {\"type\": \"string\"},\n",
        "    },\n",
        "    \"required\": [\"corrected_entry\", \"changes_summary\"],\n",
        "}\n",
        "# ----------------------------------\n",
        "\n",
        "# -----------------------\n",
        "# Data I/O Utilities (Persistence Layer)\n",
        "# -----------------------\n",
        "def load_json(path: str) -> Optional[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Loads a single JSON entry from the specified path.\n",
        "    Handles file existence and JSON decoding errors.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(path):\n",
        "        print(f\"Error: JSON file not found at {path}\")\n",
        "        return None\n",
        "    try:\n",
        "        with open(path, \"r\", encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "            # Handles if the JSON file contains a list of objects (common format)\n",
        "            return data if not isinstance(data, list) else data[0] if data else None\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"Error decoding JSON from {path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def save_json(data: Dict[str, Any], path: str):\n",
        "    \"\"\"\n",
        "    Saves the corrected entry back to the JSON file.\n",
        "    Uses indentation (indent=2) for readability.\n",
        "    \"\"\"\n",
        "    with open(path, \"w\", encoding='utf-8') as f:\n",
        "        # Saving as a list containing a single object for consistency\n",
        "        content_to_save = [data] if isinstance(data, dict) else data\n",
        "        json.dump(content_to_save, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "# -----------------------\n",
        "# PDF Parsing Utilities (Ground Truth Layer)\n",
        "# -----------------------\n",
        "def prune_text(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Cleans raw text extracted from the PDF by standardizing whitespace.\n",
        "    Removes excessive newlines and spaces, and strips leading/trailing space.\n",
        "    \"\"\"\n",
        "    text = re.sub(r'\\n+', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "def fetch_pdf_text(file_path: str) -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Reads all text content from a local PDF file using PyMuPDF (fitz) and cleans it.\n",
        "    This acts as the agent fetching the ground truth data.\n",
        "    \"\"\"\n",
        "    print(f\"   üìÑ Reading text from PDF: {file_path}\")\n",
        "    try:\n",
        "        if not os.path.exists(file_path):\n",
        "            raise FileNotFoundError(f\"PDF not found at: {file_path}\")\n",
        "\n",
        "        doc = fitz.open(file_path)\n",
        "        full_text = \"\"\n",
        "        for page in doc:\n",
        "            full_text += page.get_text()\n",
        "        doc.close()\n",
        "\n",
        "        return prune_text(full_text)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error reading PDF: {e}\")\n",
        "        return None\n",
        "\n",
        "# -----------------------\n",
        "# LLM Auditor Agent (Correction Engine)\n",
        "# -----------------------\n",
        "AUDIT_PROMPT = \"\"\"\n",
        "You are a Strict Data Auditor. Your task is to compare the 'Incorrect Local Entry' with the 'Official Ground Truth' extracted from a PDF. You must generate a corrected entry.\n",
        "\n",
        "CRITICAL INSTRUCTIONS:\n",
        "1. **ONLY CHANGE WHAT IS FACTUALLY WRONG.** If a value (like a headline or a point in a list) is correct according to the Official Ground Truth, you MUST leave it exactly as it is in the Incorrect Local Entry.\n",
        "2. If you cannot find a certain detail (e.g., a specific date), **DO NOT CHANGE** the existing value in the Local Entry.\n",
        "3. The final output must be a valid JSON object with the keys \"corrected_entry\" and \"changes_summary\".\n",
        "4. The content of \"corrected_entry\" must be a perfect, item-for-item replication of the \"Incorrect Local Entry\", with **ONLY** the necessary factual corrections applied based on the \"Official Ground Truth\".\n",
        "\n",
        "Incorrect Local Entry:\n",
        "{local_data}\n",
        "\n",
        "Official Ground Truth (Raw Text from PDF):\n",
        "{ground_truth}\n",
        "\"\"\"\n",
        "\n",
        "def run_llm_audit(local_entry: Dict[str, Any], pdf_text: str) -> Optional[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Sends data to the Gemini API for comparison and correction.\n",
        "\n",
        "    Args:\n",
        "        local_entry: The dictionary containing the data to be audited.\n",
        "        pdf_text: The ground truth text extracted from the PDF.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary containing the corrected entry and summary, or None on failure.\n",
        "    \"\"\"\n",
        "    # Truncate PDF text if it exceeds the token limit to prevent API errors\n",
        "    MAX_TRUNCATE_SIZE = 12000\n",
        "    if len(pdf_text) > MAX_TRUNCATE_SIZE:\n",
        "        pdf_text = pdf_text[:MAX_TRUNCATE_SIZE] + \" [TRUNCATED]\"\n",
        "\n",
        "    # Format the prompt with the local data and ground truth\n",
        "    prompt = AUDIT_PROMPT.format(\n",
        "        local_data=json.dumps(local_entry, indent=2, ensure_ascii=False),\n",
        "        ground_truth=pdf_text\n",
        "    )\n",
        "\n",
        "    for attempt in range(1, MAX_RETRIES + 1):\n",
        "        try:\n",
        "            # Call the Gemini API, enforcing JSON output using the defined schema\n",
        "            response = client.models.generate_content(\n",
        "                model=MODEL,\n",
        "                contents=prompt,\n",
        "                config=genai.types.GenerateContentConfig(\n",
        "                    temperature=0.0, # Low temperature for factual, deterministic changes\n",
        "                    response_mime_type=\"application/json\",\n",
        "                    response_schema=RESPONSE_SCHEMA\n",
        "                ),\n",
        "            )\n",
        "\n",
        "            # The API guarantees response.text is valid JSON matching the schema\n",
        "            content = response.text\n",
        "            parsed = json.loads(content)\n",
        "            return parsed\n",
        "\n",
        "        except (APIError, json.JSONDecodeError) as e:\n",
        "            # Handle API or JSON structure errors\n",
        "            print(f\"‚ùå LLM Error (Attempt {attempt}): {e}\")\n",
        "            if attempt == MAX_RETRIES:\n",
        "                return None\n",
        "            time.sleep(1) # Wait before retrying\n",
        "        except Exception as e:\n",
        "             # Handle other unexpected errors\n",
        "             print(f\"General Error (Attempt {attempt}): {e}\")\n",
        "             if attempt == MAX_RETRIES:\n",
        "                 return None\n",
        "             time.sleep(1)\n",
        "\n",
        "    return None\n",
        "\n",
        "# -----------------------\n",
        "# Main Audit Agent (Orchestrator)\n",
        "# -----------------------\n",
        "def run_agent(interactive: bool = True):\n",
        "    \"\"\"\n",
        "    The main agent function orchestrating the entire audit process.\n",
        "\n",
        "    Args:\n",
        "        interactive: If True, prompts the user before saving changes.\n",
        "    \"\"\"\n",
        "    # 1. Load Data (using Data I/O utility)\n",
        "    local_entry = load_json(JSON_PATH)\n",
        "    if not local_entry:\n",
        "        return # Exit if data cannot be loaded\n",
        "\n",
        "    # 2. Load Ground Truth (using PDF parsing utility)\n",
        "    pdf_text = fetch_pdf_text(PDF_PATH)\n",
        "    if not pdf_text:\n",
        "        print(\"üõë Critical: PDF text could not be loaded. Aborting audit.\")\n",
        "        return # Exit if PDF text is unavailable\n",
        "\n",
        "    print(\"\\nüîç Starting Audit and Correction...\")\n",
        "\n",
        "    # 3. Run LLM Audit (calling the LLM Auditor Agent)\n",
        "    audit_result = run_llm_audit(local_entry, pdf_text)\n",
        "\n",
        "    if not audit_result:\n",
        "        print(\"   ‚ùå Failed to get a valid correction result from LLM. Aborting.\")\n",
        "        return # Exit if LLM call fails\n",
        "\n",
        "    summary = audit_result.get(\"changes_summary\", \"No summary provided.\")\n",
        "    corrected_entry = audit_result[\"corrected_entry\"]\n",
        "\n",
        "    # 4. Compare and Decide on Update\n",
        "    # Comparison uses sorted JSON dumps to ensure that order differences in lists/dicts\n",
        "    # don't trigger a false change alert, focusing only on content differences.\n",
        "    if json.dumps(local_entry, sort_keys=True) != json.dumps(corrected_entry, sort_keys=True):\n",
        "        print(\"\\n   ‚ö° CHANGE DETECTED!\")\n",
        "        print(f\"   Summary of changes: {summary}\")\n",
        "\n",
        "        if interactive:\n",
        "            confirm = input(\"\\n      Apply this correction? (y/n): \").lower().strip()\n",
        "        else:\n",
        "            confirm = \"y\"\n",
        "\n",
        "        if confirm == 'y':\n",
        "            # Update the entry using the Data I/O utility\n",
        "            save_json(corrected_entry, JSON_PATH)\n",
        "            print(f\"\\n      ‚úÖ Saved corrected data to {JSON_PATH}.\")\n",
        "        else:\n",
        "            print(\"      ‚úã Skipped. File not modified.\")\n",
        "    else:\n",
        "        print(\"\\n   ‚úÖ Local data is already correct. No changes detected.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Check for placeholder API key before running the main function\n",
        "    if \"YOUR_GEMINI_API_KEY_HERE\" in GEMINI_API_KEY:\n",
        "         print(\"üö® WARNING: Please set the GEMINI_API_KEY environment variable or replace the placeholder in the code.\")\n",
        "    run_agent(interactive=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eA3TaQzH6Mv",
        "outputId": "ba25cb24-e455-4b79-c5d4-ee415e36acf9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   üìÑ Reading text from PDF: scheme_pdf.pdf\n",
            "\n",
            "üîç Starting Audit and Correction...\n",
            "\n",
            "   ‚úÖ Local data is already correct. No changes detected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UrrD-5ZmI2fa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kzgyAUvTP4oZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
